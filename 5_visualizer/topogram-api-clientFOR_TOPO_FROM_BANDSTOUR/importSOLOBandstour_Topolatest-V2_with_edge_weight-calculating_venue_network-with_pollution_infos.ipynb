{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from topogram_client import TopogramAPIClient\n",
    "\n",
    "from csv import DictReader\n",
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "#import musicbrainzngs\n",
    "import arrow\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from collections import defaultdict\n",
    "from dateutil import parser\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "import time\n",
    "from slugify import slugify\n",
    "from fuzzywuzzy import fuzz\n",
    "import urllib\n",
    "import math\n",
    "\n",
    "##SET PATH TO SAVE FILES:\n",
    "savpath=\"./bands_dicts/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to have a range of colors for nodes/edges \n",
    "import colorsys\n",
    "def get_N_HexCol(N=20):\n",
    "\n",
    "    HSV_tuples = [(x*1.0/N, 0.5, 0.5) for x in xrange(N)]\n",
    "    hex_out = []\n",
    "    for rgb in HSV_tuples:\n",
    "        rgb = map(lambda x: int(x*255),colorsys.hsv_to_rgb(*rgb))\n",
    "        hex_out.append(\"\".join(map(lambda x: chr(x).encode('hex'),rgb)))\n",
    "    return hex_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topogram(title, nodes, edges):\n",
    "\n",
    "    print \"Creating topogram '%s'\"%title\n",
    "\n",
    "    try :\n",
    "        r = topogram.create_topogram(title)\n",
    "    except ValueError:\n",
    "        print '> Topogram already exists'\n",
    "        r = topogram.get_topogram_by_name(title)\n",
    "    print r\n",
    "    topogram_ID = r[\"data\"][\"_id\"]\n",
    "    print \"topogram ID : %s\"%topogram_ID\n",
    "\n",
    "    # get and backup existing nodes and edges\n",
    "    existing_nodes = topogram.get_nodes(topogram_ID)[\"data\"]\n",
    "    existing_edges = topogram.get_edges(topogram_ID)[\"data\"]\n",
    "\n",
    "    # clear existing graph\n",
    "    if len(existing_nodes):\n",
    "        topogram.delete_nodes([n[\"_id\"] for n in existing_nodes])\n",
    "        print \"%s nodes deleted\"%len(existing_nodes)\n",
    "    if len(existing_edges):\n",
    "        topogram.delete_edges([n[\"_id\"] for n in existing_edges])\n",
    "        print \"%s edges deleted\"%len(existing_edges)\n",
    "\n",
    "    r = topogram.create_nodes(topogram_ID, nodes)\n",
    "    #print r\n",
    "    print \"%s nodes created.\"%len(r[\"data\"])\n",
    "    r = topogram.create_edges(topogram_ID, edges)\n",
    "    print \"%s edges created.\"%len(r[\"data\"])\n",
    "\n",
    "    print \"done. Topogram has been updated. Check it at %s/topograms/%s\"%(TOPOGRAM_URL, topogram_ID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artist={}\n",
    "artist[\"name\"]=\"steve-aoki\"\n",
    "artist[\"mbid\"]=\"a39acc4a-985e-4173-a9ed-f325f2d3bc1c\"\n",
    "\n",
    "with open(\"../../4_miner/tour_miner/\"+slugify(artist[\"name\"]+artist[\"mbid\"])+\".obj\", 'rb') as handle:\n",
    "          tempL= pickle.load( handle)\n",
    "print tempL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###HERE WE BUILD A LABEL OWNERSHIP CRUSHER FACTORIZED\n",
    "with open(\"../../4_miner/labels_aliases_TOTAL.obj\", 'rb') as handle:\n",
    "          tempRelAll= pickle.load( handle)\n",
    "def find_owning_label(label):\n",
    "    \n",
    "    labrels=[]\n",
    "    if \"label-relation-list\" in tempRelAll[label][\"label\"] :\n",
    "\n",
    "        for relat in tempRelAll[label][\"label\"][\"label-relation-list\"]:\n",
    "            if \"direction\" in relat and relat[\"direction\"] == \"backward\":\n",
    "                print tempRelAll[label][\"label\"][\"name\"],\"OWNED BY\",relat[\"target\"],\" \",tempRelAll[relat[\"target\"]][\"label\"][\"name\"]\n",
    "                labrels.append(relat[\"target\"])\n",
    "                rum_and_whisky=\"\"\n",
    "                while rum_and_whisky != \"SELF\": \n",
    "                    rum_and_whisky=find_owning_label(relat[\"target\"])\n",
    "                print \"ENDED LOOP\"\n",
    "                labrels.remove(relat[\"target\"])\n",
    "                print \"LABRELS\",labrels\n",
    "                #if labrels[0]==relat[\"target\"]:\n",
    "                 #   break\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        \n",
    "        if not labrels :\n",
    "            print \"TOP OF THE TREE FOR \",tempRelAll[label][\"label\"][\"name\"]\n",
    "            return \"SELF\"\n",
    "        else:\n",
    "            return labrels\n",
    "                \n",
    "\n",
    "\n",
    "artist={}\n",
    "artist[\"name\"]=\"Steve Aoki\"\n",
    "artist[\"mbid\"]=\"a39acc4a-985e-4173-a9ed-f325f2d3bc1c\"\n",
    "\n",
    "with open(\"../../4_miner/release_mbnz/\"+artist[\"name\"]+artist[\"mbid\"]+\".obj\", 'rb') as handle:\n",
    "          tempRelz= pickle.load( handle)\n",
    "#print tempRel[\"release-list\"][0]['label-info-list'][0]['label']['id']\n",
    "#print tempRel[\"release-list\"][0]['release-event-list'][0][\"date\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for release in tempRelz[\"release-list\"]:\n",
    "    print\"---------------------------\"\n",
    "    print release['label-info-list'][0]['label']['id']\n",
    "    print release['label-info-list'][0]['label']['name']\n",
    "    print release['release-event-list'][0][\"date\"]\n",
    "    \n",
    "    #print tempRelAll[release['label-info-list'][0]['label']['id']][\"label\"]\n",
    "    try:\n",
    "        result_lab=find_owning_label(release['label-info-list'][0]['label']['id'])\n",
    "        print \"REZLAB\",result_lab \n",
    "        print\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    except KeyError as e:\n",
    "        #print e\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIPPED PROCESSING BUT TAKING INTO ACCOUNT  Bad Brains\n"
     ]
    }
   ],
   "source": [
    "# setup mongo\n",
    "client = MongoClient()\n",
    "db = client[\"bandstour\"]\n",
    "bandsintown =  db[\"minedArtists\"]\n",
    "\n",
    "# credentials\n",
    "TOPOGRAM_URL = \"https://app.topogram.io\"\n",
    "USER = \"gregory.bahde@laposte.net\"\n",
    "PASSWORD = \"matrix\"\n",
    "\n",
    "# data\n",
    "#title = \"Foo Fighters bandstour 0.1\"\n",
    "my_nodesdict = {}\n",
    "my_nodes= []\n",
    "my_edges = []\n",
    "my_edgesdict = {}\n",
    "my_nodesdictGLOBAL={}\n",
    "\n",
    "#LIVENATION CATALOGUE\n",
    "liste_salles_LN = json.load(open('./JSON_LIVENATION_VENUE.json'))\n",
    "\n",
    "liste_salle_parsee_LN={}\n",
    "for salle in liste_salles_LN:\n",
    "    if liste_salles_LN[salle][\"type\"]==\"venue\":\n",
    " \n",
    "            liste_salle_parsee_LN[slugify(liste_salles_LN[salle][\"title\"])]={\"lat\":liste_salles_LN[salle][\"position\"][\"lat\"],\"lng\":liste_salles_LN[salle][\"position\"][\"lng\"]}\n",
    "#print liste_salle_parsee_LN\n",
    "\n",
    "\n",
    "# date parsing\n",
    "DATETIME_FORMAT = '%Y-%m-%dT%H:%M:%S'\n",
    "DATETIME_FORMAT_FOR_MSBNZ ='%Y-%m-%d'\n",
    "\n",
    "#retrieve trip coords for each artist\n",
    "dict_coords={}\n",
    "colors_for_nodes_and_edges = get_N_HexCol()\n",
    "\n",
    "#for artist in db.minedArtists.find({\"totalKm\": {\"$gte\": 250000}}) :\n",
    "for artist in db.minedArtists.find({\"name\" : \"Bad Brains\"}) :\n",
    " title = artist[\"name\"]   \n",
    " if os.path.exists(savpath+slugify(artist[\"name\"]+str(artist[\"mbid\"]))+\".obj\")==True:\n",
    "        my_nodesdict = {}\n",
    "        my_nodesdictList=[]\n",
    "        print \"SKIPPED PROCESSING BUT TAKING INTO ACCOUNT \",artist[\"name\"]\n",
    "        with open(savpath+slugify(artist[\"name\"]+str(artist[\"mbid\"]))+\".obj\", 'rb') as handle:\n",
    "          tempL= pickle.load( handle)\n",
    "    #print \n",
    "        tit=tempL[0].encode(\"utf-8\")\n",
    "        #edgestop=temp[2]\n",
    "        my_nodesdictList=tempL[1]\n",
    "        for node in my_nodesdictList:\n",
    "            my_nodesdict[node[\"data\"][\"id\"]]=node\n",
    "\n",
    "        #print my_nodes\n",
    "        #pass\n",
    " else:\n",
    "    my_nodesdict = {}\n",
    "    my_nodes= []\n",
    "    my_edges = []\n",
    "    my_nodesdictList=[]\n",
    "    my_edgesdict = {}\n",
    "    #colors_for_nodes_and_edges = get_N_HexCol()\n",
    "    \n",
    "    print artist[\"name\"]\n",
    "    #print artist\n",
    "    dates_coords = []\n",
    "    dates = artist.get(\"gigs\")\n",
    "    tours = artist.get(\"tours\")    \n",
    "    singlegigs = artist.get(\"singleGigs\")\n",
    "    dateini=0\n",
    "    touring=0\n",
    "    tour_indice=0\n",
    "    tour_counter_for_CO2=1\n",
    "    tour_counter_for_CO2_lock=0\n",
    "    tmpOLDgig ={}\n",
    "    with open(\"../../4_miner/tour_miner/\"+slugify(artist[\"name\"]+str(artist[\"mbid\"]))+\".obj\", 'rb') as handle:\n",
    "                    tempCO2= pickle.load( handle)\n",
    "    #print tempCO2\n",
    "    #print tours\n",
    "    for tour in tours:\n",
    "        \n",
    "        ##WE NEED TO MATCH TOUR INDICES OF CO2 SPECS FILES...\n",
    "     if tour_counter_for_CO2_lock == 1:\n",
    "        tour_counter_for_CO2+=1\n",
    "     tour_counter_for_CO2_lock=0\n",
    "     tour_color = \"#\"+colors_for_nodes_and_edges[tour_indice % 20]\n",
    "     #print tour_color\n",
    "     #print tour\n",
    "     gig_indice =0\n",
    "     dates = tour.get(\"gigs\")\n",
    "     for date in dates:\n",
    "        #print date.get(\"datetime\")\n",
    "        venue = date.get(\"venue\")\n",
    "        latitude = venue.get(\"latitude\")\n",
    "        longitude = venue.get(\"longitude\")\n",
    "        #print venue\n",
    "        ###concat key\n",
    "        idd= slugify(venue[\"name\"])+str(int(venue[\"latitude\"]))+str(int(venue[\"longitude\"]))\n",
    "        \n",
    "        if idd not in my_nodesdict:\n",
    "            \n",
    "            node = {\n",
    "                    \"id\" : idd,\n",
    "                    \"name\" : slugify(venue[\"name\"]),\n",
    "                    \"lat\" : float(venue[\"latitude\"]),\n",
    "                    \"lng\" : float(venue[\"longitude\"]),\n",
    "                    \"weight\" : float(1),\n",
    "                    \"start\" : date.get(\"datetime\").isoformat(),\n",
    "                    \"end\" : (date.get(\"datetime\")+timedelta(days=1)).isoformat(),\n",
    "                    \"color\" : tour_color,\n",
    "                    \"notes\" : \"name : \"+slugify(venue[\"name\"])+\"  \\nlat : \"+str(float(venue[\"latitude\"]))+\"  \\nlng :\"+str(float(venue[\"longitude\"]))+\"  \\n weight :\"+str(1)+\"  \\nstart : \"+str(date.get(\"datetime\").isoformat())+\"  \\nend : \"+str((date.get(\"datetime\")+timedelta(days=1)).isoformat())+\"  \\ncolor :\"+str(tour_color)+\"  \\n  <a href=\\\"https://google.com/search?q=\"+slugify(venue[\"name\"])+\"\\\" target=\\\"_blank\\\">\"+slugify(venue[\"name\"])+\"</a>\"\n",
    "                #+\"  \\n[search venue named \"+slugify(venue[\"name\"])+\" on google](https://google.com/search?q=\"+slugify(venue[\"name\"])+\")\"\n",
    "                    }\n",
    "        else:\n",
    "                \n",
    "                node = {\n",
    "                    \"id\" : idd,\n",
    "                    \"name\" : slugify(venue[\"name\"]),\n",
    "                    \"lat\" : float(venue[\"latitude\"]),\n",
    "                    \"lng\" : float(venue[\"longitude\"]),\n",
    "                    \"weight\" : math.sqrt(float(my_nodesdict[idd][\"data\"].get(\"weight\"))+1) ,\n",
    "                    \"start\" : my_nodesdict[idd][\"data\"].get(\"start\"),\n",
    "                    \"end\" : (date.get(\"datetime\")+timedelta(days=1)).isoformat(),\n",
    "                    \"color\" : tour_color,\n",
    "                    \"notes\" : \"name : \"+slugify(venue[\"name\"])+\"  \\nlat : \"+str(float(venue[\"latitude\"]))+\"  \\nlng :\"+str(float(venue[\"longitude\"]))+\"  \\n weight :\"+str((float(my_nodesdict[idd][\"data\"].get(\"weight\"))+1)**2)+\"  \\nstart : \"+str(my_nodesdict[idd][\"data\"].get(\"start\"))+\"  \\nend : \"+(date.get(\"datetime\")+timedelta(days=1)).isoformat()+\"  \\ncolor :\"+tour_color+\"  \\n  <a href=\\\"https://google.com/search?q=\"+slugify(venue[\"name\"])+\"\\\" target=\\\"_blank\\\">\"+slugify(venue[\"name\"])+\"</a>\"\n",
    "                    #+\"  \\n[search venue named \"+slugify(venue[\"name\"])+\" on google](https://google.com/search?q=\"+slugify(venue[\"name\"])+\")\"\n",
    "                    \n",
    "                    }\n",
    "        if dateini == 0:\n",
    "                dateini =1\n",
    "        else:\n",
    "                #print my_nodes[-1][\"data\"][\"id\"]\n",
    "                #print dates[gig_indice-1][\"distanceToNextGig\"]\n",
    "                \n",
    "                \n",
    "                \n",
    "                notesE=\"\"\n",
    "                notesE+=\"distance : \"\n",
    "                try: \n",
    "                    notesE+=str(dates[gig_indice][\"distanceToNextGig\"])\n",
    "                except KeyError:\n",
    "                    notesE+=\"dates[gig_indice][distanceToNextGig] NOT AVAILABLE\"\n",
    "                notesE+=\" km  \\n\"\n",
    "                notesE+=\"source : \"\n",
    "                notesE+=str(my_nodes[-1][\"data\"][\"id\"])\n",
    "                notesE+=\"  target : \"\n",
    "                notesE+=str(node[\"id\"])\n",
    "                notesE+=\"  \\ndatesource : \"\n",
    "                notesE+=dates[gig_indice -1][\"datetime\"].isoformat()\n",
    "                notesE+=\"  \\ndatetarget : \"\n",
    "                notesE+=dates[gig_indice][\"datetime\"].isoformat()\n",
    "                notesE+=\"  \\ngroup: \"\n",
    "                notesE+=str(int(tour_indice)+1)\n",
    "                #notesE+=\n",
    "                \n",
    "                \n",
    "                #print gig_indice\n",
    "                edge = {\n",
    "                    \"source\" : my_nodes[-1][\"data\"][\"id\"],\n",
    "                    \"target\" : node[\"id\"],\n",
    "                    \"color\" :  tour_color,\n",
    "                    \"notes\" : notesE,\n",
    "                    #\"weight\" : float(e[\"weight\"]),\n",
    "                    \"start\" : dates[gig_indice -1][\"datetime\"].isoformat(),\n",
    "                    \"end\" : dates[gig_indice][\"datetime\"].isoformat(),\n",
    "                    \"group\" : str(tour_counter_for_CO2)\n",
    "                    \n",
    "                }\n",
    "                #print edge\n",
    "                #ADDING EDGES GROUPS/CO2 HERE\n",
    "                \n",
    "                if tour[\"nbGigs\"] > 2:\n",
    "                    try:\n",
    "                        if tempCO2[tour_counter_for_CO2]['tourdist'] > 1.25*tempCO2[tour_counter_for_CO2]['tourdistOpt']:\n",
    "                            \n",
    "                            edge[\"group\"]+=\" DASHED2\"\n",
    "                            edge[\"notes\"]+=\"  \\n tournée grandement optimisable  \\nDistance parcourue pendant le tour: \"+str(tempCO2[tour_counter_for_CO2]['tourdist'])+\" km  \\n\"\n",
    "                            edge[\"notes\"]+=\"Distance recalculée: \"+str(tempCO2[tour_counter_for_CO2]['tourdistOpt'])+\" km  \\n\"\n",
    "                            try:\n",
    "                                edge[\"notes\"]+=\"Taux d'optimisation \"+str((tempCO2[tour_counter_for_CO2]['tourdist']-tempCO2[tour_counter_for_CO2]['tourdistOpt'])/tempCO2[tour_counter_for_CO2]['tourdist'])+\" %\"\n",
    "                            except:\n",
    "                                print \"OUPS 2\"\n",
    "                        elif (tempCO2[tour_counter_for_CO2]['tourdist'] < 1.25*tempCO2[tour_counter_for_CO2]['tourdistOpt']) and (tempCO2[tour_counter_for_CO2]['tourdist'] > 1.1*tempCO2[tour_counter_for_CO2]['tourdistOpt']):\n",
    "                            \n",
    "                            edge[\"group\"]+=\" DASHED1\"\n",
    "                            edge[\"notes\"]+=\"  \\n  tournée optimisable  \\nDistance parcourue pendant le tour: \"+str(tempCO2[tour_counter_for_CO2]['tourdist'])+\" km  \\n\"\n",
    "                            edge[\"notes\"]+=\"Distance recalculée: \"+str(tempCO2[tour_counter_for_CO2]['tourdistOpt'])+\" km  \\n\"\n",
    "                            try:\n",
    "                                edge[\"notes\"]+=\"Taux d'optimisation \"+str((tempCO2[tour_counter_for_CO2]['tourdist']-tempCO2[tour_counter_for_CO2]['tourdistOpt'])/tempCO2[tour_counter_for_CO2]['tourdist'])+\" %\"\n",
    "                            except:\n",
    "                                print \"OUPS 1\"\n",
    "                        elif tempCO2[tour_counter_for_CO2]['tourdistOpt'] > 1.25*tempCO2[tour_counter_for_CO2]['tourdist']:\n",
    "                            \n",
    "                            edge[\"group\"]+=\" DASHED-2\"\n",
    "                            edge[\"notes\"]+=\"  \\n tournée déjà grandement optimisée  \\nDistance parcourue pendant le tour: \"+str(tempCO2[tour_counter_for_CO2]['tourdist'])+\" km  \\n\"\n",
    "                            edge[\"notes\"]+=\"Distance recalculée: \"+str(tempCO2[tour_counter_for_CO2]['tourdistOpt'])+\" km  \\n\"\n",
    "                            try:\n",
    "                                edge[\"notes\"]+=\"Taux d'optimisation \"+str((tempCO2[tour_counter_for_CO2]['tourdist']-tempCO2[tour_counter_for_CO2]['tourdistOpt'])/tempCO2[tour_counter_for_CO2]['tourdist'])+\" %\"\n",
    "                            except:\n",
    "                                print \"OUPS -2\"\n",
    "                        elif tempCO2[tour_counter_for_CO2]['tourdistOpt'] < 1.25*tempCO2[tour_counter_for_CO2]['tourdist'] and tempCO2[tour_counter_for_CO2]['tourdistOpt'] > 1.1*tempCO2[tour_counter_for_CO2]['tourdist']:\n",
    "                            \n",
    "                            edge[\"group\"]+=\" DASHED-1\"\n",
    "                            edge[\"notes\"]+=\"  \\n  tournée déjà optimisée  \\nDistance parcourue pendant le tour: \"+str(tempCO2[tour_counter_for_CO2]['tourdist'])+\" km  \\n\"\n",
    "                            edge[\"notes\"]+=\"Distance recalculée: \"+str(tempCO2[tour_counter_for_CO2]['tourdistOpt'])+\" km  \\n\"\n",
    "                            try:\n",
    "                                edge[\"notes\"]+=\"Taux d'optimisation \"+str((tempCO2[tour_counter_for_CO2]['tourdist']-tempCO2[tour_counter_for_CO2]['tourdistOpt'])/tempCO2[tour_counter_for_CO2]['tourdist'])+\" %\"\n",
    "                            except:\n",
    "                                print \"OUPS -1\"\n",
    "                        \n",
    "                        else:\n",
    "\n",
    "                            edge[\"notes\"]+=\"  \\nDistance parcourue pendant le tour: \"+str(tempCO2[tour_counter_for_CO2]['tourdist'])+\" km  \\n\"\n",
    "                        tour_counter_for_CO2_lock=1\n",
    "                    except KeyError as e:\n",
    "                        print e\n",
    "                else:\n",
    "                    #print \"TOUR NON COMPTE \", tour_indice, \"//\",tour_counter_for_CO2\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                my_edges.append({ \"data\" : edge })\n",
    "        my_nodes.append({ \"data\" : node })   \n",
    "        my_nodesdict[node[\"id\"]]= { \"data\" : node }\n",
    "        gig_indice+=1\n",
    "    #print my_nodes\n",
    "    #print \"<=============================================>\"\n",
    "    #print my_nodesdict\n",
    "    #print \"<=============================================>\"\n",
    "    #print my_edges\n",
    "     tour_indice +=1\n",
    "        #print \"coords\",latitude,\"/\",longitude\n",
    "    for key, value in my_nodesdict.iteritems():\n",
    "            my_nodesdictList.append(value)\n",
    "    \n",
    "    #ADDING LIVENATION DETECTOR\n",
    "\n",
    "    for node in my_nodesdictList:\n",
    "        for salle in liste_salle_parsee_LN:\n",
    "            if fuzz.partial_ratio( node['data']['name'], salle)>=80:\n",
    "                #print \"ONE HEERE\"\n",
    "                if round(node['data']['lat'],2)==round(liste_salle_parsee_LN[salle][\"lat\"],2) and round(node['data']['lng'],2)==round(liste_salle_parsee_LN[salle][\"lng\"],2) :\n",
    "                    #print \"CONFIRMED LIVENATION!\"\n",
    "                    node['data']['color']=\"#ff0000\"\n",
    "                    node['data'][\"notes\"]+=\"  \\nLivenation venue\"\n",
    "        #if liste_salle_parsee_LN\n",
    "        \n",
    "        \n",
    "    #ADDING EDGES WEIGHT\n",
    "    terp= map(lambda x : str(sorted([x[\"data\"][\"source\"],x[\"data\"][\"target\"]])),my_edges)\n",
    "    \n",
    "    #print terp\n",
    "    from collections import Counter\n",
    "    c= Counter()\n",
    "    for ter in terp:\n",
    "        c[ter]+=1\n",
    "    #print c\n",
    "    for edge in my_edges:\n",
    "        if str(sorted([edge[\"data\"][\"source\"],edge[\"data\"][\"target\"]])) not in terp:\n",
    "            print \"BUG!!!!\"\n",
    "        else:\n",
    "            if edge[\"data\"][\"source\"] == edge[\"data\"][\"target\"]:\n",
    "                #print c[str(sorted([edge[\"data\"][\"source\"],edge[\"data\"][\"target\"]]))]\n",
    "                edge[\"data\"][\"notes\"]+=\"  \\ncounted \"+str(c[str(sorted([edge[\"data\"][\"source\"],edge[\"data\"][\"target\"]]))])+\"  times\"\n",
    "                edge[\"data\"][\"weight\"]= float(1)\n",
    "                #print \"a\"\n",
    "            else:\n",
    "                edge[\"data\"][\"notes\"]+=\"  \\ncounted \"+str(c[str(sorted([edge[\"data\"][\"source\"],edge[\"data\"][\"target\"]]))])+\"  times\"\n",
    "                edge[\"data\"][\"weight\"]= float(c[str(sorted([edge[\"data\"][\"source\"],edge[\"data\"][\"target\"]]))])\n",
    "                #print \"b\"\n",
    "    #print my_edges\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    titredugraphe =artist[\"name\"]+\"/BETA_0.4\"+\"  \\nDistance totale parcourue par l'artiste: \"+str(tempCO2[\"totalArtistTourDist\"])+\" km\"\n",
    "    titredugraphe += \"  \\nDistance calculee par Concorde: \"+str(tempCO2[\"totalArtistOptTourDist\"])+\" km\"\n",
    "    if  \"OptArtistPercent\" in tempCO2 :\n",
    "         rateOpt=0\n",
    "         rateOpt=float(tempCO2[\"OptArtistPercent\"])\n",
    "         titredugraphe+=\"  \\nPourcentage d'optimisation global calcule:\"+str(rateOpt)+\" %\"\n",
    "         if rateOpt > 10: \n",
    "             titredugraphe+=\"  \\nMARGE D'OPTIMISATION IMPORTANTE\"\n",
    "         elif rateOpt < -10:\n",
    "              titredugraphe+=\"  \\nTOURNEE DEJA OPTIMISEE\"\n",
    "         else: \n",
    "             titredugraphe+=\"  \\nGLOBALEMENT IDENTIQUE\"\n",
    "         \n",
    "         \n",
    "    with open(savpath+slugify(artist[\"name\"]+str(artist[\"mbid\"]))+\".obj\", 'wb') as handle:\n",
    "                            pickle.dump([titredugraphe,my_nodesdictList,my_edges], handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "            \n",
    "    ###CREATE NODE GLOBAL DICT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "     with open(\"./my_nodesdictGLOBAL.obj\", 'rb') as handle:\n",
    "          my_nodesdictGLOBAL= pickle.load( handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pete-s-place32-117', {'data': {'count': 1, 'end': '2017-04-01T19:00:00', 'name': 'pete-s-place', 'weight': 1.0, 'color': '#7f523f', 'notes': '  \\n List of the bands that played in this venue:  \\nblack-joe-lewis  \\n TOTAL: 1 Bands', 'start': '2017-03-31T19:00:00', 'lat': 32.7677778, 'lng': -117.0222222, 'id': 'pete-s-place32-117'}}), ('tucson-music-hall32-110', {'data': {'count': 35, 'end': '2018-01-15T14:00:00', 'name': 'tucson-music-hall', 'weight': 7.158396516477644, 'color': '#3f7f6c', 'notes': '  \\n List of the bands that played in this venue:  \\ncherish-the-ladies  \\nitzhak-perlman  \\nbill-maher  \\ncurtis-stigers  \\njonathan-richman  \\nthe-lettermen  \\npiotr-ilich-chaikovskii  \\nthe-midtown-men  \\njoseph-haydn  \\ngeorge-lopez  \\nsuper-diamond  \\njane-s-addiction  \\nlindsey-stirling  \\narturo-sandoval  \\nlewis-black  \\ndon-giovanni  \\njerry-seinfeld  \\nkt-tunstall  \\nvideo-games-live  \\nthe-ten-tenors  \\nbellamy-brothers-band  \\nbrian-regan  \\nmichael-feinstein  \\nrain  \\njackson-browne  \\nwilco  \\nthe-1975  \\njohn-pizzarelli  \\njohn-legend  \\njames-taylor  \\ncarmina-burana  \\nceltic-woman  \\njudy-collins  \\npink-martini  \\njoe-bonamassa  \\n TOTAL: 35 Bands', 'start': '2007-12-17T00:00:00', 'lat': 32.2216667, 'lng': -110.9258333, 'id': 'tucson-music-hall32-110'}}), ('bluegrass-festival37-107', {'data': {'count': 1, 'end': '2008-04-14T19:00:00', 'name': 'bluegrass-festival', 'weight': 1.5537739740300374, 'color': '#3f7f46', 'notes': '  \\n List of the bands that played in this venue:  \\nthe-infamous-stringdusters  \\n TOTAL: 1 Bands', 'start': '2008-04-11T19:00:00', 'lat': 37.2752778, 'lng': -107.8794444, 'id': 'bluegrass-festival37-107'}}), ('salle-des-dominicains440', {'data': {'count': 2, 'end': '2013-07-22T18:00:00', 'name': 'salle-des-dominicains', 'weight': 2.19736822693562, 'color': '#3f7f46', 'notes': '  \\n List of the bands that played in this venue:  \\nchic  \\nchick-corea  \\n TOTAL: 2 Bands', 'start': '2013-07-18T18:00:00', 'lat': 44.895123, 'lng': -0.155287, 'id': 'salle-des-dominicains440'}}), ('gem-brunch42-71', {'data': {'count': 1, 'end': '2015-05-04T16:00:00', 'name': 'gem-brunch', 'weight': 1.4142135623730951, 'color': '#727f3f', 'notes': '  \\n List of the bands that played in this venue:  \\nchachi  \\n TOTAL: 1 Bands', 'start': '2015-03-29T17:00:00', 'lat': 42.3569387, 'lng': -71.0599056, 'id': 'gem-brunch42-71'}})]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "print take(5,my_nodesdictGLOBAL.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials\n",
    "TOPOGRAM_URL = \"http://localhost:3000\"\n",
    "USER = \"gregory.bahde@laposte.net\"\n",
    "PASSWORD = \"matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(my_nodesdictGLOBAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# connect to the topogram instance (pass debug=True params for more info )\n",
    "topogram = TopogramAPIClient(TOPOGRAM_URL) #, debug=True)\n",
    "\n",
    "# create a new user\n",
    "try :\n",
    "    topogram.create_user(USER, PASSWORD)\n",
    "except ValueError:\n",
    "    print \"> User has already been created.\"\n",
    "\n",
    "# login a new user if needed\n",
    "resp_user_login = topogram.user_login(USER, PASSWORD)\n",
    "print resp_user_login\n",
    "\n",
    "assert(resp_user_login[\"status\"] == \"success\")\n",
    "assert(resp_user_login[\"status_code\"] == 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/goonieb/gitrep/bandstour/5_visualizer/topogram-api-clientFOR_TOPO_FROM_BANDSTOUR\n",
      "Creating topogram 'Dead Kennedys/BETA_0.4  \n",
      "Distance totale parcourue par l'artiste: 49960.3182228 km  \n",
      "Distance calculee par Concorde: 50365.355494 km  \n",
      "Pourcentage d'optimisation global calcule:-0.810717957032 %  \n",
      "GLOBALEMENT IDENTIQUE'\n",
      "{u'status': u'success', 'status_code': 200, u'data': u'HsyMd7vY7CqkHJLqZ', u'statusCode': 201}\n",
      "Creating topogram 'Dead Kennedys/BETA_0.4  \n",
      "Distance totale parcourue par l'artiste: 49960.3182228 km  \n",
      "Distance calculee par Concorde: 50365.355494 km  \n",
      "Pourcentage d'optimisation global calcule:-0.810717957032 %  \n",
      "GLOBALEMENT IDENTIQUE'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:topogram-client:500 - Error : A topogram with the same name already exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Topogram already exists\n",
      "{u'status': u'success', 'status_code': 200, u'data': {u'sharedPublic': False, u'title': u\"Dead Kennedys/BETA_0.4  \\nDistance totale parcourue par l'artiste: 49960.3182228 km  \\nDistance calculee par Concorde: 50365.355494 km  \\nPourcentage d'optimisation global calcule:-0.810717957032 %  \\nGLOBALEMENT IDENTIQUE\", u'userId': u'BgWEdXXGnvEq2Hodg', u'_id': u'HsyMd7vY7CqkHJLqZ', u'slug': u'dead-kennedysbeta_04-distance-totale-parcourue-par-lartiste-499603182228-km-distance-calculee-par-concorde-50365355494-km-pourcentage-doptimisation-global-calcule-0810717957032-globalement-identique', u'createdAt': u'2018-06-02T09:01:03.660Z'}, u'statusCode': 200}\n",
      "topogram ID : HsyMd7vY7CqkHJLqZ\n",
      "96 nodes created.\n",
      "106 edges created.\n",
      "done. Topogram has been updated. Check it at http://localhost:3000/topograms/HsyMd7vY7CqkHJLqZ\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "###IMPORT ALL THE BANDS GRAPHS\n",
    "\n",
    "nodestop=[]\n",
    "edgestop=[]\n",
    "tit=[]\n",
    "import glob, os\n",
    "\n",
    "print os.getcwd()\n",
    "\n",
    "file= \"./bands_dicts/dead-kennedys37c78aeb-d196-42b5-b991-6afb4fc9bc2e.obj\"\n",
    "with open(file, 'rb') as handle:\n",
    "          temp= pickle.load( handle)\n",
    "    #print \n",
    "tit=temp[0].encode(\"utf-8\")\n",
    "edgestop=temp[2]\n",
    "nodestop=temp[1]\n",
    "    #print edgestop\n",
    "    #for edge in edgestop:\n",
    "    #    assert edge[\"data\n",
    "while True:\n",
    "        try:\n",
    "            #print\n",
    "            create_topogram(tit, nodestop, edgestop)\n",
    "        except TypeError:\n",
    "            continue\n",
    "        break\n",
    "print 'DONE'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:topogram-client:500 - Error : A topogram with the same name already exists\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 nodes deleted\n",
      "5000 nodes created.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-19a8f878a201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mnodestopo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mcreate_topogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodestopo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgestopo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2d6e9028f27d>\u001b[0m in \u001b[0;36mcreate_topogram\u001b[0;34m(title, nodes, edges)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#print r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%s nodes created.\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopogram_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%s edges created.\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goonieb/anaconda2/lib/python2.7/site-packages/topogram_client/__init__.pyc\u001b[0m in \u001b[0;36mcreate_edges\u001b[0;34m(self, topogramId, edges)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;34m\"\"\"POST Create a bunch of edges. Returns the created edges\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"edges\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"topogramId\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtopogramId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"edges\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goonieb/anaconda2/lib/python2.7/site-packages/topogram_client/__init__.pyc\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(self, method, path, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m# handle 403 error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s - Error : %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goonieb/anaconda2/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goonieb/anaconda2/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goonieb/anaconda2/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goonieb/anaconda2/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No JSON object could be decoded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "###IMPORT THE GLOBAL VENUE  GRAPH\n",
    "my_nodesdictList=[]\n",
    "nodestopo=[]\n",
    "edgestopo=[]\n",
    "with open(\"./my_nodesdictGLOBAL.obj\", 'rb') as handle:\n",
    "          my_nodesdictGLOBAL= pickle.load( handle)\n",
    "        \n",
    "for key, value in my_nodesdictGLOBAL.iteritems():\n",
    "            my_nodesdictGLOBAL[key][\"data\"].pop('count')\n",
    "        \n",
    "for key, value in my_nodesdictGLOBAL.iteritems():\n",
    "            my_nodesdictList.append(value)\n",
    "        \n",
    "nodestopo=sorted(my_nodesdictList, key= lambda (v) : v['data']['weight'], reverse=True)[:5000]\n",
    "print len(nodestopo)\n",
    "\n",
    "\n",
    "\n",
    "title=\"global venue graph /BETA 0.3\"\n",
    "\n",
    "while True:\n",
    "        try:\n",
    "            print nodestopo\n",
    "            create_topogram(title, nodestopo, edgestopo)\n",
    "        \n",
    "        except TypeError:\n",
    "            continue\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
